{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics      import mean_absolute_error\n",
    "from datetime             import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "DATA_PATH = '../data'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "VALID_PATH = os.path.join(DATA_PATH, 'valid.csv')\n",
    "\n",
    "CATEGORY_COLUMNS = ['credit_card_level', 'aff_type', 'country_segment']\n",
    "DATE_COLUMNS = ['join_date']\n",
    "NUMBER_COLUMNS = ['user_id', 'hidden', 'STV', 'target', 'is_lp', 'is_cancelled']\n",
    "\n",
    "FEATURES_COLUMNS = ['join_date', 'hidden', 'STV', 'credit_card_level',\n",
    "                    'is_lp', 'aff_type', 'is_cancelled', 'country_segment']\n",
    "TARGET_COLUMN = 'target'\n",
    "\n",
    "NULL_CATEGORY_KEY = 'Unknown'\n",
    "NULL_CATEGORY_VALUE = -1\n",
    "\n",
    "NULL_NUMBER_VALUE = -1\n",
    "NULL_DATE_VALUE = datetime.date(1000,1,1)\n",
    "\n",
    "DTYPE_CATEGORY_COLUMNS = {'credit_card_level': 'category', \n",
    "                          'aff_type': 'category', \n",
    "                          'country_segment': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(path, \n",
    "                    parse_dates = DATE_COLUMNS, \n",
    "                    dtype = DTYPE_CATEGORY_COLUMNS)\n",
    "# Read Data\n",
    "train = read_csv(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371727 entries, 0 to 371726\n",
      "Data columns (total 10 columns):\n",
      "user_id              371727 non-null int64\n",
      "join_date            371727 non-null datetime64[ns]\n",
      "hidden               371727 non-null int64\n",
      "STV                  371727 non-null float64\n",
      "target               371727 non-null float64\n",
      "credit_card_level    371727 non-null category\n",
      "is_lp                371727 non-null int64\n",
      "aff_type             371727 non-null category\n",
      "is_cancelled         371727 non-null int64\n",
      "country_segment      371727 non-null category\n",
      "dtypes: category(3), datetime64[ns](1), float64(2), int64(4)\n",
      "memory usage: 20.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_map_from_categories(data, columns, map_categories = None):\n",
    "    global NULL_CATEGORY_KEY, NULL_CATEGORY_VALUE\n",
    "    \n",
    "    if map_categories is None:\n",
    "        map_categories = dict()\n",
    "        for col in columns:\n",
    "            labels = data[col].astype('category').cat.categories.tolist()\n",
    "            map_categories[col] = {k: v for k,v in zip(labels, list(range(1,len(labels)+1)))}\n",
    "            map_categories[col][NULL_CATEGORY_KEY] = NULL_CATEGORY_VALUE\n",
    "    else : \n",
    "        for col in columns:\n",
    "            labels = data[col].astype('category').cat.categories.tolist()\n",
    "            new_labels = [label for label in labels if label not in list(map_categories[col].keys())]\n",
    "            if new_labels:\n",
    "                next_value = max(map_categories[col].values())+1\n",
    "                map_categories[col].update({k: v for k,v in zip(new_labels,\n",
    "                                                                list(range(next_value, next_value+len(new_labels)+1)))})\n",
    "    return map_categories\n",
    "\n",
    "\n",
    "def preprocessing(data, map_categories = None):\n",
    "    global CATEGORY_COLUMNS, DATE_COLUMNS, NUMBER_COLUMNS, NULL_DATE_VALUE, NULL_NUMBER_VALUE\n",
    "    preprocessed = data.copy()\n",
    "    \n",
    "    for date_column in DATE_COLUMNS:\n",
    "        # Check NaT values and convert them to timestamp\n",
    "        preprocessed[date_column] = preprocessed[date_column].apply(\n",
    "                                    lambda x: NULL_DATE_VALUE.timestamp() \n",
    "                                                if x is pd.NaT else x.timestamp())\n",
    "    \n",
    "    for category_column in CATEGORY_COLUMNS:\n",
    "        # Check NaN values and convert them to NULL_CATEGORY_KEY\n",
    "        preprocessed[category_column] = preprocessed[category_column].cat \\\n",
    "                                                .add_categories(NULL_CATEGORY_KEY) \\\n",
    "                                                .fillna(NULL_CATEGORY_KEY)\n",
    "\n",
    "        \n",
    "    # Convert categories to codes\n",
    "    map_categories = create_or_update_map_from_categories(data, CATEGORY_COLUMNS, map_categories)\n",
    "    preprocessed.replace(map_categories, inplace = True)\n",
    "    \n",
    "    for number_column in NUMBER_COLUMNS:\n",
    "         # Check NaN values and convert them to NULL_NUMBER_VALUE\n",
    "        preprocessed[number_column] = preprocessed[number_column].apply(\n",
    "                                            lambda x: NULL_NUMBER_VALUE if pd.isna(x) else x)\n",
    "    \n",
    "    \n",
    "    return preprocessed, map_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, map_categories = preprocessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit_card_level': {'prepaid': 1, 'standard': 2, 'Unknown': -1},\n",
       " 'aff_type': {'Other': 1, 'PPL': 2, 'PPS': 3, 'Unknown': -1},\n",
       " 'country_segment': {'AU': 1,\n",
       "  'CL': 2,\n",
       "  'EC': 3,\n",
       "  'GB': 4,\n",
       "  'ID': 5,\n",
       "  'IL': 6,\n",
       "  'IN': 7,\n",
       "  'KZ': 8,\n",
       "  'MY': 9,\n",
       "  'NG': 10,\n",
       "  'NZ': 11,\n",
       "  'RU': 12,\n",
       "  'SA': 13,\n",
       "  'SG': 14,\n",
       "  'TH': 15,\n",
       "  'TR': 16,\n",
       "  'UA': 17,\n",
       "  'US': 18,\n",
       "  'ZA': 19,\n",
       "  'Unknown': -1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>join_date</th>\n",
       "      <th>hidden</th>\n",
       "      <th>STV</th>\n",
       "      <th>target</th>\n",
       "      <th>credit_card_level</th>\n",
       "      <th>is_lp</th>\n",
       "      <th>aff_type</th>\n",
       "      <th>is_cancelled</th>\n",
       "      <th>country_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1.543623e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1.543623e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     join_date  hidden     STV  target credit_card_level  is_lp  \\\n",
       "0        0  1.543622e+09       1  0.3975  0.3975                 1      0   \n",
       "1        1  1.543622e+09       0  0.3975  0.3975                 2      0   \n",
       "2        2  1.543622e+09       0  0.3975  0.3975                 2      0   \n",
       "3       11  1.543623e+09       1  0.3975  0.3975                 1      0   \n",
       "4       17  1.543623e+09       0  0.3975  0.3975                 2      0   \n",
       "\n",
       "  aff_type  is_cancelled country_segment  \n",
       "0        3             1              18  \n",
       "1        3             1              18  \n",
       "2        3             1              18  \n",
       "3        2             1              18  \n",
       "4        2             0              18  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateVIF(data) :\n",
    "    \"\"\"\n",
    "    Calculate VIF (Variance Inflation Factor) of data. \n",
    "    \n",
    "    VIF allows us cuantify the intensity of multicollinearity. The VIF value increases according\n",
    "    to the multicollinearity increases. The VIF values bigger than 5 are considered high and\n",
    "    VIF values bigger than 10 are considered very high.\n",
    "    \n",
    "    Params:\n",
    "    data -- data.\n",
    "    \n",
    "    Returns:\n",
    "    A dataframe with the VIF value of each feature.\n",
    "    \"\"\"\n",
    "    features = list(data.columns)\n",
    "    num_features = len(features)\n",
    "    \n",
    "    # Create the model and the result dataframe\n",
    "    model = LinearRegression()\n",
    "    result = pd.DataFrame(index = ['VIF'], columns = features)\n",
    "    result = result.fillna(0)\n",
    "    \n",
    "    # For each feature\n",
    "    for ite in range(num_features) :\n",
    "        x_features = features[:]\n",
    "        y_feature  = features[ite]\n",
    "        # Remove the feature (because it is the independient)\n",
    "        x_features.remove(y_feature)\n",
    "        \n",
    "        x = data[x_features]\n",
    "        y = data[y_feature]\n",
    "        \n",
    "        # Fit the model \n",
    "        model.fit(x, y)\n",
    "        # Calculate VIF\n",
    "        result[y_feature] = 1 / (1 - model.score(x, y))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def selectFeaturesUsingVIF(data, max_VIF = 5) :\n",
    "    \"\"\"\n",
    "    Select features using its VIF value.\n",
    "    \n",
    "    Params:\n",
    "    data -- data.\n",
    "    max_VIF -- maximum VIF value to follow removing features.\n",
    "    \n",
    "    Returns:\n",
    "    A dataframe with the features selected.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy data\n",
    "    result = data.copy(deep = True)\n",
    "    \n",
    "    # Calculate VIF of all features\n",
    "    VIF = calculateVIF(result)\n",
    "    \n",
    "    # While the VIF value is bigger than max_VIF:\n",
    "    while VIF.values.max() > max_VIF :\n",
    "        # Get the column of the feature which gets the maximum VIF\n",
    "        col_max = np.where(VIF == VIF.values.max())[1][0]\n",
    "        \n",
    "        # Remove this feature of the data\n",
    "        features = list(result.columns)\n",
    "        features.remove(features[col_max])\n",
    "        result = result[features]\n",
    "        \n",
    "        # Again, calculate VIF\n",
    "        VIF = calculateVIF(result)\n",
    "\n",
    "    # Return the result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>join_date</th>\n",
       "      <th>hidden</th>\n",
       "      <th>STV</th>\n",
       "      <th>credit_card_level</th>\n",
       "      <th>is_lp</th>\n",
       "      <th>aff_type</th>\n",
       "      <th>is_cancelled</th>\n",
       "      <th>country_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.543623e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.543623e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      join_date  hidden     STV credit_card_level  is_lp aff_type  \\\n",
       "0  1.543622e+09       1  0.3975                 1      0        3   \n",
       "1  1.543622e+09       0  0.3975                 2      0        3   \n",
       "2  1.543622e+09       0  0.3975                 2      0        3   \n",
       "3  1.543623e+09       1  0.3975                 1      0        2   \n",
       "4  1.543623e+09       0  0.3975                 2      0        2   \n",
       "\n",
       "   is_cancelled country_segment  \n",
       "0             1              18  \n",
       "1             1              18  \n",
       "2             1              18  \n",
       "3             1              18  \n",
       "4             0              18  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = train[TARGET_COLUMN]\n",
    "train_features = train[FEATURES_COLUMNS]\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>join_date</th>\n",
       "      <th>hidden</th>\n",
       "      <th>STV</th>\n",
       "      <th>credit_card_level</th>\n",
       "      <th>is_lp</th>\n",
       "      <th>aff_type</th>\n",
       "      <th>is_cancelled</th>\n",
       "      <th>country_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.543622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.543623e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.543623e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      join_date  hidden     STV credit_card_level  is_lp aff_type  \\\n",
       "0  1.543622e+09       1  0.3975                 1      0        3   \n",
       "1  1.543622e+09       0  0.3975                 2      0        3   \n",
       "2  1.543622e+09       0  0.3975                 2      0        3   \n",
       "3  1.543623e+09       1  0.3975                 1      0        2   \n",
       "4  1.543623e+09       0  0.3975                 2      0        2   \n",
       "\n",
       "   is_cancelled country_segment  \n",
       "0             1              18  \n",
       "1             1              18  \n",
       "2             1              18  \n",
       "3             1              18  \n",
       "4             0              18  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = selectFeaturesUsingVIF(train_features)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no multicollinearity in train_features, so keep FEATURES_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's metrics are:\n",
      "Trainning R^2 =  0.6376326892097208\n",
      "MAE =  3.717517283540668\n"
     ]
    }
   ],
   "source": [
    "# Create a model and fit it with de train data\n",
    "model = LinearRegression()\n",
    "model.fit(train_features, train_target)\n",
    "\n",
    "# Let's predict the train data\n",
    "pred = model.predict(train_features)\n",
    "\n",
    "print(\"The model's metrics are:\")\n",
    "print('Trainning R^2 = ', model.score(train_features, train_target))\n",
    "print('MAE = ', mean_absolute_error(pred, train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation (all dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit_card_level': {'prepaid': 1, 'standard': 2, 'Unknown': -1},\n",
       " 'aff_type': {'Other': 1, 'PPL': 2, 'PPS': 3, 'Unknown': -1},\n",
       " 'country_segment': {'AU': 1,\n",
       "  'CL': 2,\n",
       "  'EC': 3,\n",
       "  'GB': 4,\n",
       "  'ID': 5,\n",
       "  'IL': 6,\n",
       "  'IN': 7,\n",
       "  'KZ': 8,\n",
       "  'MY': 9,\n",
       "  'NG': 10,\n",
       "  'NZ': 11,\n",
       "  'RU': 12,\n",
       "  'SA': 13,\n",
       "  'SG': 14,\n",
       "  'TH': 15,\n",
       "  'TR': 16,\n",
       "  'UA': 17,\n",
       "  'US': 18,\n",
       "  'ZA': 19,\n",
       "  'Unknown': -1,\n",
       "  'CA': 20}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read valid dataset\n",
    "valid = read_csv(VALID_PATH)\n",
    "# Preprocessing\n",
    "valid_preprocessed, map_categories = preprocessing(valid, map_categories)\n",
    "map_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's metrics are:\n",
      "Validation R^2 =  0.6274331639546528\n",
      "MAE =  4.1402298970781795\n"
     ]
    }
   ],
   "source": [
    "valid_features = valid_preprocessed[FEATURES_COLUMNS]\n",
    "valid_target = valid_preprocessed[TARGET_COLUMN]\n",
    "\n",
    "# Let's predict the valid data\n",
    "pred = model.predict(valid_features)\n",
    "\n",
    "print(\"The model's metrics are:\")\n",
    "print('Validation R^2 = ', model.score(valid_features, valid_target))\n",
    "print('MAE = ', mean_absolute_error(pred, valid_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation (aggregated dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>join_date</th>\n",
       "      <th>country_segment</th>\n",
       "      <th>hidden</th>\n",
       "      <th>credit_card_level</th>\n",
       "      <th>is_lp</th>\n",
       "      <th>aff_type</th>\n",
       "      <th>is_cancelled</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.265875</td>\n",
       "      <td>64.262072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>1.268290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.714500</td>\n",
       "      <td>255.983722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.855125</td>\n",
       "      <td>22.119294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.385000</td>\n",
       "      <td>11.135028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   join_date  country_segment  hidden  credit_card_level  is_lp  aff_type  \\\n",
       "0 2019-07-01                1       0                  2      0         2   \n",
       "1 2019-07-01                1       0                  2      0         2   \n",
       "2 2019-07-01                1       0                  2      0         3   \n",
       "3 2019-07-01                1       0                  2      0         3   \n",
       "4 2019-07-01                1       0                  2      1         2   \n",
       "\n",
       "   is_cancelled      target        pred  \n",
       "0           0.0  126.265875   64.262072  \n",
       "1           1.0    0.795000    1.268290  \n",
       "2           0.0  279.714500  255.983722  \n",
       "3           1.0   19.855125   22.119294  \n",
       "4           0.0    2.385000   11.135028  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_column = 'pred'\n",
    "\n",
    "# Add prediction to valid_preprocessed dataset\n",
    "valid_preprocessed[pred_column] = pred\n",
    "\n",
    "# Truncate join_date column by day/month/year\n",
    "valid_preprocessed['join_date'] = valid_preprocessed['join_date']\\\n",
    "                .apply(lambda x: dt.fromtimestamp(x).replace(hour=0, minute=0, second=0, microsecond=0))\n",
    "\n",
    "# Aggregate dataset\n",
    "valid_aggregated = valid_preprocessed.groupby(['join_date', 'country_segment', 'hidden', \n",
    "                                               'credit_card_level', 'is_lp', \n",
    "                                               'aff_type', 'is_cancelled'], as_index = False)\\\n",
    "                                     .agg({TARGET_COLUMN: 'sum', pred_column: 'sum'})\n",
    "\n",
    "valid_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'country_segment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'country_segment'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e644cbde01fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate MAE for each country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountry_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_aggregated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_aggregated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry_segment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcountry_codes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_aggregated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_aggregated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry_segment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcountry_codes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'country_segment'"
     ]
    }
   ],
   "source": [
    "country_segment = 'country_segment'\n",
    "country_codes = map_categories[country_segment]\n",
    "\n",
    "# Calculate MAE for each country\n",
    "for country in country_codes:\n",
    "    pred = valid_aggregated[valid_aggregated[country_segment] == country_codes[country]][pred_column]\n",
    "    valid_target = valid_aggregated[valid_aggregated[country_segment] == country_codes[country]][TARGET_COLUMN]\n",
    "    \n",
    "    if not pred.empty:\n",
    "        print(\"The model's metrics for country\", country, \"are:\")\n",
    "        print('MAE = ', mean_absolute_error(pred, valid_target))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
